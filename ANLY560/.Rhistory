xlab("Year")+
ylab("Invest")+
scale_color_manual(values = c("Beijing"="purple","Hunan"="grey50"),
breaks = c("Beijing","Hunan"))+
ggtitle("Beijing_Hunan Province estate month invest (100 million)")
# HW3_models
# df_Beijing_log
# sarima(df_Beijing_log, 1,1,1,0,1,1,11)
# (mae1 <- abs(mean(as.numeric(pred$mean)-as.numeric((test))))): 0.006486547
accuracy(f3)
accuracy(f3)
# HW3_models
# df_Beijing_log
# sarima(df_Beijing_log, 1,1,1,0,1,1,11)
length(df_Beijing_log) #194
# HW3_models
df_Beijing_log <- log(df_Beijing.ts)
# sarima(df_Beijing_log, 1,1,1,0,1,1,11)
length(df_Beijing_log) #194
train=ts(df_Beijing_log[1:150], frequency = 11)
test=ts(df_Beijing_log[151:194], frequency = 11)
fit <- Arima(train,order = c(1,1,1), seasonal = c(0,1,1),include.drift = TRUE)
summary(fit)
pred=forecast(fit,44)
accuracy(pred)
# (mae1 <- abs(mean(as.numeric(pred$mean)-as.numeric((test))))): 0.006486547
accuracy(pred)
(mae1 <- abs(mean(as.numeric(pred$mean)-as.numeric((test)))))
accuracy(pred)
write.csv(df_Beijing_log, file = "hw5_dataset.csv")
# Do a seasonal cross validation using 1 step ahead forecasts and s (your seasonal period)  steps ahead forecasts.
# SARIMA(1,1,1)(0,1,1)[11]
# 11 steps ahead forecasts
head(df_Beijing_log)
mae2 <- matrix(NA,n-k,11)
# Do a seasonal cross validation using 1 step ahead forecasts and s (your seasonal period)  steps ahead forecasts.
# SARIMA(1,1,1)(0,1,1)[11]
df_Beijing_log = df_Beijing_log[1:187]
k <- 44 # minimum data length for fitting a model (4 seasonal lags)
n <- length(df_Beijing_log)
n-k #143
df_Beijing_log=ts(df_Beijing_log,frequency=11)
# 143/11=13
mae <- matrix(NA, n-k-11, 11)
st <- tsp(df_Beijing_log)[1]+(k-2)/11
# 11 steps ahead forecasts
head(df_Beijing_log)
mae2 <- matrix(NA,n-k,11)
st <- tsp(df_Beijing_log)[1]+(k-2)/11
for(i in 1:(n-k))
{
xtrain <- window(df_Beijing_log, end=st + i/11)
xtest <- window(df_Beijing_log, start=st + (i+1)/11, end=st + (i+11)/11)
fit <- Arima(xtrain, order=c(1,1,1), seasonal=list(order=c(0,1,1), period=11),
include.drift=TRUE, lambda=0, method="ML")
fcast <- forecast(fit, h=11)
mae2[i,1:length(xtest)] <- abs(fcast$mean-xtest)
}
# plot
plot(1:11, colMeans(mae2,na.rm=TRUE), type="l", col=2, xlab="horizon", ylab="MAE", main="Seasonal Cross Validation-11 steps ahead forecasts")
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa)
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
require(timeDate)
# ggplot2 for VIS
df_mac_industry_area_estate_invest_month <- read.csv(file = 'df_mac_industry_area_estate_invest_month.csv')
head(df_mac_industry_area_estate_invest_month)
# Beijing
df_Beijing <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='北京市') %>%
select(stat_month, invest)
ggplot(df_Beijing, aes(stat_month,invest))+geom_line(group = 1)+
ggtitle("Beijing estate month investment (100 million)") +
xlab("stat_month")+
ylab("invest")+geom_point(color="purple")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
# Hunan Province
df_Hunan <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='湖南省') %>%
select(stat_month, invest)
ggplot(df_Hunan, aes(stat_month,invest))+geom_line(group = 1)+
ggtitle("Hunan Province estate month investment (100 million)") +
xlab("stat_month")+
ylab("invest")+geom_point(color="lightgreen")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
# transform to ts data
# No January data
# Beijing
df_Beijing <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='北京市') %>%
select(invest)
df_Beijing.ts=ts(df_Beijing, start = decimal_date(as.Date("2000-02-01")),frequency = 11)
str(df_Beijing.ts)
# Hunan
df_Hunan <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='湖南省') %>%
select(invest)
df_Hunan.ts=ts(df_Hunan, start = decimal_date(as.Date("2000-02-01")),frequency = 11)
str(df_Hunan.ts)
autoplot(df_Beijing.ts, series = "Beijing")+
autolayer(df_Hunan.ts, series = "Hunan")+
xlab("Year")+
ylab("Invest")+
scale_color_manual(values = c("Beijing"="purple","Hunan"="grey50"),
breaks = c("Beijing","Hunan"))+
ggtitle("Beijing_Hunan Province estate month invest (100 million)")
# HW3_models
df_Beijing_log <- log(df_Beijing.ts)
# sarima(df_Beijing_log, 1,1,1,0,1,1,11)
length(df_Beijing_log) #194
train=ts(df_Beijing_log[1:150], frequency = 11)
test=ts(df_Beijing_log[151:194], frequency = 11)
fit <- Arima(train,order = c(1,1,1), seasonal = c(0,1,1),include.drift = TRUE)
summary(fit)
pred=forecast(fit,44)
accuracy(pred)
(mae1 <- abs(mean(as.numeric(pred$mean)-as.numeric((test)))))
# Do a seasonal cross validation using 1 step ahead forecasts and s (your seasonal period)  steps ahead forecasts.
# SARIMA(1,1,1)(0,1,1)[11]
df_Beijing_log = df_Beijing_log[1:187]
k <- 44 # minimum data length for fitting a model (4 seasonal lags)
n <- length(df_Beijing_log)
n-k #143
df_Beijing_log=ts(df_Beijing_log,frequency=11)
# 143/11=13
mae2 <- matrix(NA, n-k-11, 11)
st <- tsp(df_Beijing_log)[1]+(k-2)/11
# 11 steps ahead forecasts
head(df_Beijing_log)
mae2 <- matrix(NA,n-k,11)
st <- tsp(df_Beijing_log)[1]+(k-2)/11
for(i in 1:(n-k))
{
xtrain <- window(df_Beijing_log, end=st + i/11)
xtest <- window(df_Beijing_log, start=st + (i+1)/11, end=st + (i+11)/11)
fit <- Arima(xtrain, order=c(1,1,1), seasonal=list(order=c(0,1,1), period=11),
include.drift=TRUE, lambda=0, method="ML")
fcast <- forecast(fit, h=11)
mae2[i,1:length(xtest)] <- abs(fcast$mean-xtest)
}
# plot
plot(1:11, colMeans(mae2,na.rm=TRUE), type="l", col=2, xlab="horizon", ylab="MAE", main="Seasonal Cross Validation-11 steps ahead forecasts")
write.csv(df_Beijing_log, file = "hw5_dataset.csv")
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa)
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
require(timeDate)
# ggplot2 for VIS
df_mac_industry_area_estate_invest_month <- read.csv(file = 'df_mac_industry_area_estate_invest_month.csv')
head(df_mac_industry_area_estate_invest_month)
# Beijing
df_Beijing <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='北京市') %>%
select(stat_month, invest)
ggplot(df_Beijing, aes(stat_month,invest))+geom_line(group = 1)+
ggtitle("Beijing estate month investment (100 million)") +
xlab("stat_month")+
ylab("invest")+geom_point(color="purple")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
# Hunan Province
df_Hunan <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='湖南省') %>%
select(stat_month, invest)
ggplot(df_Hunan, aes(stat_month,invest))+geom_line(group = 1)+
ggtitle("Hunan Province estate month investment (100 million)") +
xlab("stat_month")+
ylab("invest")+geom_point(color="lightgreen")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
# transform to ts data
# No January data
# Beijing
df_Beijing <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='北京市') %>%
select(invest)
df_Beijing.ts=ts(df_Beijing, start = decimal_date(as.Date("2000-02-01")),frequency = 11)
str(df_Beijing.ts)
# Hunan
df_Hunan <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='湖南省') %>%
select(invest)
df_Hunan.ts=ts(df_Hunan, start = decimal_date(as.Date("2000-02-01")),frequency = 11)
str(df_Hunan.ts)
autoplot(df_Beijing.ts, series = "Beijing")+
autolayer(df_Hunan.ts, series = "Hunan")+
xlab("Year")+
ylab("Invest")+
scale_color_manual(values = c("Beijing"="purple","Hunan"="grey50"),
breaks = c("Beijing","Hunan"))+
ggtitle("Beijing_Hunan Province estate month invest (100 million)")
# HW3_models
df_Beijing_log <- log(df_Beijing.ts)
# sarima(df_Beijing_log, 1,1,1,0,1,1,11)
length(df_Beijing_log) #194
train=ts(df_Beijing_log[1:150], frequency = 11)
test=ts(df_Beijing_log[151:194], frequency = 11)
fit <- Arima(train,order = c(1,1,1), seasonal = c(0,1,1),include.drift = TRUE)
summary(fit)
pred=forecast(fit,44)
accuracy(pred)
(mae1 <- abs(mean(as.numeric(pred$mean)-as.numeric((test)))))
write.csv(df_Beijing_log, file = "hw5_dataset.csv")
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa)
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
require(timeDate)
# ggplot2 for VIS
df_mac_industry_area_estate_invest_month <- read.csv(file = 'df_mac_industry_area_estate_invest_month.csv')
head(df_mac_industry_area_estate_invest_month)
# Beijing
df_Beijing <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='北京市') %>%
select(stat_month, invest)
ggplot(df_Beijing, aes(stat_month,invest))+geom_line(group = 1)+
ggtitle("Beijing estate month investment (100 million)") +
xlab("stat_month")+
ylab("invest")+geom_point(color="purple")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
# Hunan Province
df_Hunan <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='湖南省') %>%
select(stat_month, invest)
ggplot(df_Hunan, aes(stat_month,invest))+geom_line(group = 1)+
ggtitle("Hunan Province estate month investment (100 million)") +
xlab("stat_month")+
ylab("invest")+geom_point(color="lightgreen")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
# transform to ts data
# No January data
# Beijing
df_Beijing <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='北京市') %>%
select(invest)
df_Beijing.ts=ts(df_Beijing, start = decimal_date(as.Date("2000-02-01")),frequency = 11)
str(df_Beijing.ts)
# Hunan
df_Hunan <- df_mac_industry_area_estate_invest_month %>%
filter(area_name=='湖南省') %>%
select(invest)
df_Hunan.ts=ts(df_Hunan, start = decimal_date(as.Date("2000-02-01")),frequency = 11)
str(df_Hunan.ts)
autoplot(df_Beijing.ts, series = "Beijing")+
autolayer(df_Hunan.ts, series = "Hunan")+
xlab("Year")+
ylab("Invest")+
scale_color_manual(values = c("Beijing"="purple","Hunan"="grey50"),
breaks = c("Beijing","Hunan"))+
ggtitle("Beijing_Hunan Province estate month invest (100 million)")
# HW3_models
df_Beijing_log <- log(df_Beijing.ts)
# sarima(df_Beijing_log, 1,1,1,0,1,1,11)
length(df_Beijing_log) #194
train=ts(df_Beijing_log[1:150], frequency = 11)
test=ts(df_Beijing_log[151:194], frequency = 11)
fit <- Arima(train,order = c(1,1,1), seasonal = c(0,1,1),include.drift = TRUE)
summary(fit)
pred=forecast(fit,44)
accuracy(pred)
(mae1 <- abs(mean(as.numeric(pred$mean)-as.numeric((test)))))
write.csv(df_Beijing_log, file = "hw5_dataset.csv")
library(gam)
library(tidyverse)
library(caret)
library(dslabs)
library(glmnet)
# load data
data <- read.csv("train.csv")
set.seed(123)
index = sample(1:nrow(data), nrow(data)/1.5)
df_train = data[index,]
df_train <- df_train[complete.cases(df_train), ]
df_test = data[-index,]
df_test <- df_test[complete.cases(df_test), ]
df_train = df_train[,9:25]
df_test = df_test[,9:25]
df_train$satisfaction <- as.factor(df_train$satisfaction)
df_test$satisfaction <- as.factor(df_test$satisfaction)
View(df_test)
colnames(df_train)
(colnames(df_train))
# logistic regression
fit1 <- glm(satisfaction ~., family = "binomial", data = df_train)
summary(fit1)
fit2 <- glm(satisfaction ~ .-Inflight.service, family = "binomial", data = df_train)
summary(fit2)
glm.probs1=predict(fit1,type="response")
glm.probs1[1:10]
glm.probs2=predict(fit2,type="response")
glm.probs2[1:10]
contrasts(df_train$satisfaction)
glm.pred1=rep("neutral or dissatisfied",nrow(df_train))
glm.pred1[glm.probs1>.5]="satisfied"
table(glm.pred1,df_train$satisfaction)
glm.pred2=rep("neutral or dissatisfied",nrow(df_train))
glm.pred2[glm.probs2>.5]="satisfied"
table(glm.pred2,df_train$satisfaction)
(33288+23112)/(33288+6805+23112+5859)
summary(fit1)
glm.probs1=predict(fit1,newdata=df_test,type="response")
# logistic regression
fit1 <- glm(satisfaction ~., family = "binomial", data = df_train)
summary(fit1)
fit2 <- glm(satisfaction ~ .-Inflight.service, family = "binomial", data = df_train)
summary(fit2)
glm.probs1=predict(fit1,newdata=df_test,type="response")
glm.probs1[1:10]
glm.probs2=predict(fit2,newdata=df_test,type="response")
glm.probs2[1:10]
contrasts(df_test$satisfaction)
glm.pred1=rep("neutral or dissatisfied",nrow(df_test))
glm.pred1[glm.probs1>.5]="satisfied"
table(glm.pred1,df_test$satisfaction)
glm.pred2=rep("neutral or dissatisfied",nrow(df_test))
glm.pred2[glm.probs2>.5]="satisfied"
table(glm.pred2,df_test$satisfaction)
(33288+23112)/(33288+6805+23112+5859)
(16648+11623)/(16648+3357+11623+2902)
# LDA
lda.fit = lda(satisfaction~., data = df_train)
library(gam)
library(tidyverse)
library(caret)
library(dslabs)
library(glmnet)
# LDA
lda.fit = lda(satisfaction~., data = df_train)
library(MASS)
# LDA
lda.fit = lda(satisfaction~., data = df_train)
lda.fit
plot(lda.fit)
# predict
lda.pred=predict(lda.fit, df_test)
names(lda.pred)
# accuracy
lda.class=lda.pred$class
table(lda.class,df_test$satisfaction)
# correct classifications
(16471+11729)/(16471+3251+3079+11729)
# QDA
qda.fit <- qda(satisfaction~., data = df_train)
qda.fit
qda.class <- predict(qda.fit,df_test)$class
table(qda.class,df_test$satisfaction)
(16612+11716)/(16612+3264+11716+2938)
# Naive Bayes
library (e1071)
nb.fit <- naiveBayes(satisfaction~., data = df_train)
nb.fit
nb.class <- predict (nb.fit, df_test)
table (nb.class, df_test$satisfaction)
(15010+12065)/(15010+2915+12065+4540)
nb.fit$tables
nb.fit$levels
str(data)
df_test[,21]
df_test[,20:21]
df_train = df_train[,9:25]
data <- read.csv("train.csv")
str(data)
set.seed(123)
index = sample(1:nrow(data), nrow(data)/1.5)
df_train = data[index,]
df_train <- df_train[complete.cases(df_train), ]
df_test = data[-index,]
df_test <- df_test[complete.cases(df_test), ]
df_train = df_train[,9:25]
View(df_train)
df_train = [,-c(15:16)]
df_train = df_train[,-c(15:16)]
(colnames(df_train))
# load data
data <- read.csv("train.csv")
str(data)
set.seed(123)
index = sample(1:nrow(data), nrow(data)/1.5)
df_train = data[index,]
df_train <- df_train[complete.cases(df_train), ]
df_test = data[-index,]
df_test <- df_test[complete.cases(df_test), ]
df_train = df_train[,9:25]
df_train = df_train[,-c(15:16)]
(colnames(df_train))
df_test = df_test[,9:25]
df_test = df_test[,-c(15:16)]
df_train$satisfaction <- as.factor(df_train$satisfaction)
df_test$satisfaction <- as.factor(df_test$satisfaction)
# logistic regression
fit1 <- glm(satisfaction ~., family = "binomial", data = df_train)
summary(fit1)
fit2 <- glm(satisfaction ~ .-Inflight.service, family = "binomial", data = df_train)
summary(fit2)
glm.probs1=predict(fit1,newdata=df_test,type="response")
glm.probs1[1:10]
glm.probs2=predict(fit2,newdata=df_test,type="response")
glm.probs2[1:10]
contrasts(df_test$satisfaction)
glm.pred1=rep("neutral or dissatisfied",nrow(df_test))
glm.pred1[glm.probs1>.5]="satisfied"
table(glm.pred1,df_test$satisfaction)
glm.pred2=rep("neutral or dissatisfied",nrow(df_test))
glm.pred2[glm.probs2>.5]="satisfied"
table(glm.pred2,df_test$satisfaction)
(16648+11623)/(16648+3357+11623+2902)
contrasts(df_test$satisfaction)
# logistic regression
fit1 <- glm(satisfaction ~., family = "binomial", data = df_train)
summary(fit1)
fit2 <- glm(satisfaction ~ .-Inflight.service, family = "binomial", data = df_train)
summary(fit2)
glm.probs1=predict(fit1,newdata=df_test,type="response")
glm.probs1[1:10]
glm.probs2=predict(fit2,newdata=df_test,type="response")
glm.probs2[1:10]
contrasts(df_test$satisfaction)
glm.pred1=rep("neutral or dissatisfied",nrow(df_test))
glm.pred1[glm.probs1>.5]="satisfied"
table(glm.pred1,df_test$satisfaction)
glm.pred2=rep("neutral or dissatisfied",nrow(df_test))
glm.pred2[glm.probs2>.5]="satisfied"
table(glm.pred2,df_test$satisfaction)
(16648+11623)/(16648+3357+11623+2902)
# LDA
lda.fit = lda(satisfaction~., data = df_train)
lda.fit
plot(lda.fit)
# predict
lda.pred=predict(lda.fit, df_test)
names(lda.pred)
# accuracy
lda.class=lda.pred$class
table(lda.class,df_test$satisfaction)
# correct classifications
(16471+11729)/(16471+3251+3079+11729)
library(tidyverse)
library(dplyr)
library(plotly)
library(ggplot2)
# for height
gdp <- read.csv("data/athlete_events.csv",skip = 4)
gdp <- read.csv("data/athlete_events.csv")
# for height
athlete <- read.csv("data/athlete_events.csv")
View(athlete)
library(tidyverse)
library(plotly)
library(ggplot2)
athlete <- read.csv("athlete_events.csv")
library(tidyverse)
library(plotly)
library(ggplot2)
athlete <- read.csv("data/athlete_events.csv")
head(athlete)
#remove duplicate values
athlete2 <- athlete[!duplicated(athlete$Name), ]
head(athlete2)
#keep only Name, Age, Height, Weight, Medal
athlete3 <- athlete2 [ , c("Year", "Height","Weight","Medal")]
head(athlete3)
nrow(athlete3)
View(athlete3)
#keep only Name, Age, Height, Weight, Medal
athlete3 <- athlete2 [ , c("Name", "Sex", "Height")]
head(athlete3)
nrow(athlete3)
View(athlete)
write_csv("athlete_height.csv")
write_csv(athlete3,"athlete_height.csv")
#remove duplicate values
athlete2 <- athlete[!duplicated(athlete$Name), ]
head(athlete2)
#keep only Name, Age, Height, Weight, Medal
athlete3 <- athlete2 [ , c("Name", "Sex", "Height")]
athlete3 <- na.omit(athlete3)
head(athlete3)
nrow(athlete3)
write_csv(athlete3,"athlete_height.csv")
